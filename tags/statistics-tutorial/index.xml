<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics Tutorial | Home</title>
    <link>/tags/statistics-tutorial/</link>
      <atom:link href="/tags/statistics-tutorial/index.xml" rel="self" type="application/rss+xml" />
    <description>Statistics Tutorial</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 07 Sep 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>Statistics Tutorial</title>
      <link>/tags/statistics-tutorial/</link>
    </image>
    
    <item>
      <title>Markov Chains Part 1</title>
      <link>/project/markovchain1/</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      <guid>/project/markovchain1/</guid>
      <description>&lt;p&gt;This post is an introduction to the Markov Chain, a common stochastic modeling framework to simulate random phenomena.&lt;/p&gt;
&lt;h2 id=&#34;a-motivating-example-susceptible-infected-susceptible-sis-model&#34;&gt;A Motivating Example: Susceptible-Infected-Susceptible (SIS) Model&lt;/h2&gt;
&lt;p&gt;At any given time, an individual is either &lt;em&gt;infected&lt;/em&gt; with a disease or is healthy, i.e. is &lt;em&gt;susceptible&lt;/em&gt; to becoming infected. Over an extended period of time (e.g. a year), an individual is likely to experience both of these &lt;em&gt;states&lt;/em&gt;. Suppose we observe an individual over a sequence of days &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=n&amp;space;=&amp;space;1,&amp;space;2,&amp;space;...&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?n&amp;space;=&amp;space;1,&amp;space;2,&amp;space;...&#34; title=&#34;n = 1, 2, ...&#34; /&gt;&lt;/a&gt; and classify this individual on day &lt;em&gt;n&lt;/em&gt; as:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=X_n&amp;space;=&amp;space;\begin{cases}&amp;space;I&amp;space;&amp;&amp;space;\text{if&amp;space;infected}\\&amp;space;S&amp;space;&amp;&amp;space;\text{if&amp;space;susceptible}\\&amp;space;\end{cases}&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?X_n&amp;space;=&amp;space;\begin{cases}&amp;space;I&amp;space;&amp;&amp;space;\text{if&amp;space;infected}\\&amp;space;S&amp;space;&amp;&amp;space;\text{if&amp;space;susceptible}\\&amp;space;\end{cases}&#34; title=&#34;X_n = \begin{cases} I &amp; \text{if infected}\\ S &amp; \text{if susceptible}\\ \end{cases}&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There is some &lt;em&gt;probability&lt;/em&gt; &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=\alpha&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?\alpha&#34; title=&#34;\alpha&#34; /&gt;&lt;/a&gt; that an infected individual remains infected the following day; in this simple scenario, there must therefore be a probability &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=1&amp;space;-&amp;space;\alpha&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?1&amp;space;-&amp;space;\alpha&#34; title=&#34;1 - \alpha&#34; /&gt;&lt;/a&gt; that the individual instead &lt;em&gt;transitions&lt;/em&gt; to the susceptible state the following day&lt;a href=&#34;#note1&#34; id=&#34;note1ref&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. Likewise, we can apply this same reasoning to deduce that a susceptible individual will remain susceptible the following day with probability &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=\beta&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?\beta&#34; title=&#34;\beta&#34; /&gt;&lt;/a&gt; or will transition to infected with probability &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=1&amp;space;-&amp;space;\beta&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?1&amp;space;-&amp;space;\beta&#34; title=&#34;1 - \beta&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;With fairly high accuracy, we can guess how an individual will feel tomorrow based only on how he/she feels today. In other words, there is no need to consider how an individual felt before day &lt;em&gt;n&lt;/em&gt; in order to guess how an individual is likely to feel on day &lt;em&gt;n + 1&lt;/em&gt;. Thus, the values of &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=\alpha&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?\alpha&#34; title=&#34;\alpha&#34; /&gt;&lt;/a&gt; and &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=\beta&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?\beta&#34; title=&#34;\beta&#34; /&gt;&lt;/a&gt; apply regardless of the individual&amp;rsquo;s health history. We call this one-step memory property the &lt;em&gt;Makrov property&lt;/em&gt;; it can be interpreted as &amp;ldquo;given the present, the future does not depend on the past.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Markov chains&lt;/em&gt; (MCs) are a type of stochastic (random) mathematical model that allows us to describe this scenario more formally. This math is useful for many reasons; for example, we can use it to compute the percentage of days that an individual is expected to be sick, or the number of individuals sick simultaneously during an epidemic.&lt;/p&gt;
&lt;h2 id=&#34;mathematical-notation&#34;&gt;Mathematical Notation&lt;/h2&gt;
&lt;p&gt;Formally, a Markov Chain is a stochastic process on the &lt;em&gt;state space&lt;/em&gt; &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=S&amp;space;=&amp;space;\{1,&amp;space;2,&amp;space;\dots,&amp;space;s\}&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?S&amp;space;=&amp;space;\{1,&amp;space;2,&amp;space;\dots,&amp;space;s\}&#34; title=&#34;S = \{1, 2, \dots, s\}&#34; /&gt;&lt;/a&gt; (i.e. the chain has &lt;em&gt;s&lt;/em&gt; possible states) that has one-step memory. Importantly, the Markov chain assumes a &lt;em&gt;discrete&lt;/em&gt; state-space&lt;a href=&#34;#note2&#34; id=&#34;note1ref&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;. The &lt;em&gt;transtion probability&lt;/em&gt; from state &lt;em&gt;i&lt;/em&gt; to state &lt;em&gt;j&lt;/em&gt; is given by:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=\mathcal{P}(X_n&amp;space;=&amp;space;j&amp;space;|&amp;space;X_{n-1}&amp;space;=&amp;space;i,&amp;space;X_{n-2}&amp;space;=&amp;space;x_{n-2},&amp;space;\dots,&amp;space;X_0&amp;space;=&amp;space;x_o)&amp;space;=&amp;space;\mathcal{P}(X_n&amp;space;=&amp;space;j&amp;space;|&amp;space;X_{n-1}&amp;space;=&amp;space;i)&amp;space;=&amp;space;P_{ij}&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?\mathcal{P}(X_n&amp;space;=&amp;space;j&amp;space;|&amp;space;X_{n-1}&amp;space;=&amp;space;i,&amp;space;X_{n-2}&amp;space;=&amp;space;x_{n-2},&amp;space;\dots,&amp;space;X_0&amp;space;=&amp;space;x_o)&amp;space;=&amp;space;\mathcal{P}(X_n&amp;space;=&amp;space;j&amp;space;|&amp;space;X_{n-1}&amp;space;=&amp;space;i)&amp;space;=&amp;space;P_{ij}&#34; title=&#34;\mathcal{P}(X_n = j | X_{n-1} = i, X_{n-2} = x_{n-2}, \dots, X_0 = x_o) = \mathcal{P}(X_n = j | X_{n-1} = i) = P_{ij}&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Translating from math-speak to English: the probability that the Markov Chain will be in state &lt;em&gt;j&lt;/em&gt; at time-step &lt;em&gt;n&lt;/em&gt; &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=X_n&amp;space;=&amp;space;j&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?X_n&amp;space;=&amp;space;j&#34; title=&#34;X_n = j&#34; /&gt;&lt;/a&gt; given (| is read as &amp;ldquo;given&amp;rdquo;) that the Markov Chain is in state &lt;em&gt;i&lt;/em&gt; at time-step &lt;em&gt;n-1&lt;/em&gt;, i.e. &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=X_{n-1}&amp;space;=&amp;space;i&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?X_{n-1}&amp;space;=&amp;space;i&#34; title=&#34;X_{n-1} = i&#34; /&gt;&lt;/a&gt; depends &lt;em&gt;only&lt;/em&gt; on the fact that &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=X_{n-1}&amp;space;=&amp;space;i&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?X_{n-1}&amp;space;=&amp;space;i&#34; title=&#34;X_{n-1} = i&#34; /&gt;&lt;/a&gt; and we can ignore all previous realizations of the Markov Chain.&lt;/p&gt;
&lt;h2 id=&#34;back-to-the-sis-model-constructing-the-transition-probablity-matrix&#34;&gt;Back to the SIS Model: Constructing the Transition Probablity Matrix&lt;/h2&gt;
&lt;p&gt;There are two states in the SIS model: &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=S&amp;space;=&amp;space;\{Infected,&amp;space;Susceptible\}&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?S&amp;space;=&amp;space;\{Infected,&amp;space;Susceptible\}&#34; title=&#34;S = \{Infected, Susceptible\}&#34; /&gt;&lt;/a&gt; The transition probabilities are &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=\alpha&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?\alpha&#34; title=&#34;\alpha&#34; /&gt;&lt;/a&gt; &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=1&amp;space;-&amp;space;\alpha&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?1&amp;space;-&amp;space;\alpha&#34; title=&#34;1 - \alpha&#34; /&gt;&lt;/a&gt; &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=\beta&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?\beta&#34; title=&#34;\beta&#34; /&gt;&lt;/a&gt; and &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=1&amp;space;-&amp;space;\beta&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?1&amp;space;-&amp;space;\beta&#34; title=&#34;1 - \beta&#34; /&gt;&lt;/a&gt; as defined above, leading to the following &lt;em&gt;transition probability matrix&lt;/em&gt; (TPM):&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=\mathbf{P}&amp;space;=&amp;space;\begin{bmatrix}&amp;space;\alpha&amp;space;&amp;&amp;space;1&amp;space;-&amp;space;\alpha&amp;space;\\&amp;space;1&amp;space;-&amp;space;\beta&amp;space;&amp;&amp;space;\beta&amp;space;\end{bmatrix}&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?\mathbf{P}&amp;space;=&amp;space;\begin{bmatrix}&amp;space;\alpha&amp;space;&amp;&amp;space;1&amp;space;-&amp;space;\alpha&amp;space;\\&amp;space;1&amp;space;-&amp;space;\beta&amp;space;&amp;&amp;space;\beta&amp;space;\end{bmatrix}&#34; title=&#34;\mathbf{P} = \begin{bmatrix} \alpha &amp; 1 - \alpha \\ 1 - \beta &amp; \beta \end{bmatrix}&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The rows of this matrix correspond to the current state (an individual&amp;rsquo;s infection status today), while the columns of this matrix correspond to the next state (an individual&amp;rsquo;s infection status tomorrow). Each entry of this matrix, therefore, represents the probability that a transition from state &lt;em&gt;i&lt;/em&gt; to state &lt;em&gt;j&lt;/em&gt; will occur in a single step. It is a specific example of a &lt;em&gt;probabilistic matrix&lt;/em&gt;, which has the properties of rows that sum to 1 and entries that are bounded between 0 and 1.&lt;/p&gt;
&lt;p&gt;Transition probability matrices are necessary for most of the &amp;ldquo;useful&amp;rdquo; math associated with MCs. As a brief example, multiplying the TPM by itself yields the 2-step transition probability matrix, which in the SIS example, represents the probability an individual has infection status &lt;em&gt;j&lt;/em&gt; the &lt;em&gt;day after tomorrow&lt;/em&gt;, given that the individual currently has infection status &lt;em&gt;i&lt;/em&gt;&lt;a href=&#34;#note1&#34; id=&#34;note3ref&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;odes-and-mcs-a-comparison&#34;&gt;ODEs and MCs: A Comparison&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://larnold1997.github.io/project/sir_model/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Elsewhere,&lt;/a&gt;
 I have presented a very similar model for infectious diseases using ordinary differential equations (ODEs). Both frameworks are equally valid and can be used to answer many of the same questions. However, there is a notable difference between these two types of models. An ODE model is deterministic, i.e. it will &lt;em&gt;always&lt;/em&gt; yield the same answer using the same parameters and set of initial conditions. MCs, on the other hand, are &lt;em&gt;stochastic&lt;/em&gt;, i.e. they are based in randomness, and any values obtained using MCs must be assessed probabilistically. Therefore, before applying either framework, a modeler must decide what type of answer they hope to get for their research question(s).&lt;/p&gt;
&lt;p&gt;&lt;a id=&#34;note1&#34; href=&#34;#note1ref&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; Recall from basic probability that if one of two events always occurs, then the probability that each of them occurs must sum to 1.&lt;/p&gt;
&lt;p&gt;&lt;a id=&#34;note2&#34; href=&#34;#note1ref&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; In the context of the SIS example, this means an individual is either susceptible or infected; there is no intermediate state.&lt;/p&gt;
&lt;p&gt;&lt;a id=&#34;note3&#34; href=&#34;#note1ref&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; In a future post, I will explore how repeating this process yields the long-term probabilities associated with the Markov chain.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How Lucky am I (Statistically)?</title>
      <link>/project/luckandprobability/</link>
      <pubDate>Mon, 30 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/project/luckandprobability/</guid>
      <description>&lt;h2 id=&#34;bernoulli-distribution&#34;&gt;Bernoulli Distribution&lt;/h2&gt;
&lt;p&gt;Coin flipping - throwing a coin into the air and checking whether heads or tails is displayed when it lands - is one of the most elementary science experiments. Even children understand that the two potential outcomes are random. In statistics, modeling this binary (i.e. yes/no) outcome is done with a &lt;em&gt;Bernoulli distribution&lt;/em&gt;. The 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Bernoulli_distribution&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bernoulli distribution&lt;/a&gt;
 is a discrete probability distribution, meaning it can only take distinct values. Specifically, we may assign &amp;ldquo;heads&amp;rdquo; to the number &amp;ldquo;1&amp;rdquo; and &amp;ldquo;tails&amp;rdquo; to the number &amp;ldquo;0&amp;rdquo;. (Nothing is preventing us from choosing the opposite assignment.) Often, statisticians choose to use &amp;ldquo;1&amp;rdquo; to represent &amp;ldquo;yes&amp;rdquo; or &amp;ldquo;success&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;Formally, the Bernoulli distribution describes a random variable that takes the value 1 with probability &lt;em&gt;p&lt;/em&gt; and the value &lt;em&gt;0&lt;/em&gt; with the probability &lt;em&gt;q = 1 - p&lt;/em&gt;. In the coin tossing example (assuming a &amp;ldquo;fair&amp;rdquo; coin), &lt;em&gt;p = q = 1/2&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&#34;binomial-distribution&#34;&gt;Binomial Distribution&lt;/h2&gt;
&lt;p&gt;You may be asking yourself: so what? It is obvious that a coin flip can yield heads or tails with equal probability. Is this formalization necessary?&lt;/p&gt;
&lt;p&gt;The benefit to approaching coin flipping (and any other binary outcome) in the lens of a Bernoulli distribution is that the Bernoulli distribution is a special example of the &lt;em&gt;binomial distribution&lt;/em&gt;. The 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Binomial_distribution&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;binomial distribution&lt;/a&gt;
 describes the probability of obtaining &lt;em&gt;k&lt;/em&gt; successes out of &lt;em&gt;n&lt;/em&gt; Bernoulli trials when the probability of success is &lt;em&gt;p&lt;/em&gt;, assuming each trial is &lt;em&gt;independent&lt;/em&gt; (i.e. the outcome of one trial does not influence the outcome of the next trial). This probability can be calculated using the probability mass function (PMF) of the binomial distribution:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=f(k,n,p)=\Pr(k;n,p)=\Pr(X=k)={\binom&amp;space;{n}{k}}p^{k}(1-p)^{n-k}&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?f(k,n,p)=\Pr(k;n,p)=\Pr(X=k)={\binom&amp;space;{n}{k}}p^{k}(1-p)^{n-k}&#34; title=&#34;f(k,n,p)=\Pr(k;n,p)=\Pr(X=k)={\binom {n}{k}}p^{k}(1-p)^{n-k}&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;for &lt;em&gt;k = 0, 1, 2, &amp;hellip;, n,&lt;/em&gt; where&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex={\binom&amp;space;{n}{k}}={\frac&amp;space;{n!}{k!(n-k)!}}&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?{\binom&amp;space;{n}{k}}={\frac&amp;space;{n!}{k!(n-k)!}}&#34; title=&#34;{\binom {n}{k}}={\frac {n!}{k!(n-k)!}}&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;is the &lt;em&gt;binomial coefficient&lt;/em&gt; (hence why the distribution is called the binomial distribution). This is much more interesting than simply asking what the probability of success and failure of the next trial is!&lt;/p&gt;
&lt;p&gt;Though the PMF can seem complicated at first, the interpretation is relatively straightforward when it is broken into its constituent parts. First, &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=p^k&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?p^k&#34; title=&#34;p^k&#34; /&gt;&lt;/a&gt; represents the probability of succeeding &lt;em&gt;k&lt;/em&gt; times when each success has probability &lt;em&gt;p&lt;/em&gt;. If there are &lt;em&gt;k&lt;/em&gt; successes in &lt;em&gt;n&lt;/em&gt; trials, then there are &lt;em&gt;n - k&lt;/em&gt; failures. Therefore, &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=(1-p)^{n-k}&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?(1-p)^{n-k}&#34; title=&#34;(1-p)^{n-k}&#34; /&gt;&lt;/a&gt; is the probability of failing &lt;em&gt;n - k&lt;/em&gt; times. Since each trial is independent, we can simply multiply these two probabilities together. Finally, the binomial coefficient at the beginning of the formula captures the fact that there are (almost always) many different ways to obtain &lt;em&gt;k&lt;/em&gt; successes; for instance, they may all be at the beginning, all at the end, or anywhere in between.&lt;/p&gt;
&lt;p&gt;Below is a graph of the binomial distribution&amp;rsquo;s PMF of a fair coin for &lt;em&gt;n = 20&lt;/em&gt; trials.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;Fig1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Unsurprisingly, the PMF is maximized when &lt;em&gt;n = 10&lt;/em&gt;: When the probability of success is equal to the probability of failure, the most likely result is an equal number of successes and failures. The beauty of the binomial distribution is that it allows us to figure out what the most likely outcome is when the outcome of the experiment is biased toward either success or failure. Indeed, the mean of a binomial distribution is always given by the product &lt;em&gt;np&lt;/em&gt;.  Moving away from the peak, the PMF decays symmetrically; this is expected due to the fact that &lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=\binom{n}{k}&amp;space;=&amp;space;\binom{n}{n-k}&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?\binom{n}{k}&amp;space;=&amp;space;\binom{n}{n-k}&#34; title=&#34;\binom{n}{k} = \binom{n}{n-k}&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Check out my 
&lt;a href=&#34;https://larnold1997.shinyapps.io/binomialpmf/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Shiny app&lt;/a&gt;
 to see how the binomial PMF changes for different values of &lt;em&gt;p&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id=&#34;geometric-distribution&#34;&gt;Geometric Distribution&lt;/h2&gt;
&lt;p&gt;To summarize the above section, the binomial distribution lets us calculate the probability of observing &lt;em&gt;k&lt;/em&gt; successes when a Bernoulli trial (i.e. a binary outcome) is observed &lt;em&gt;n&lt;/em&gt; times with a probability &lt;em&gt;p&lt;/em&gt; of success.&lt;/p&gt;
&lt;p&gt;Suppose instead that the experiment stops when it succeeds. To continue the coin flipping example, we will flip the coin until it lands heads up. This may take 1, 2, 5, 10, 100, or more trials. In general, what is the probability that this experiment will require &lt;em&gt;k&lt;/em&gt; trials? The &lt;em&gt;geometric distribution&lt;/em&gt; can be used to answer this question. Formally, the 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Geometric_distribution&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;geometric distribution&lt;/a&gt;
 gives the probability that the first occurrence of a success of &lt;em&gt;k&lt;/em&gt; independent Bernoulli trials, each with probability of success &lt;em&gt;p&lt;/em&gt;. The PMF of the geometric distribution is&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex={\displaystyle&amp;space;\Pr(X=k)=(1-p)^{k-1}p}&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?{\displaystyle&amp;space;\Pr(X=k)=(1-p)^{k-1}p}&#34; title=&#34;{\displaystyle \Pr(X=k)=(1-p)^{k-1}p}&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;for &lt;em&gt;k = 1, 2, 3&amp;hellip;&lt;/em&gt;. The interpretation of this formula is similar to the PMF of the binomial distribution above: If the first success is on trial &lt;em&gt;k&lt;/em&gt;, then the first &lt;em&gt;k - 1&lt;/em&gt; trials are failures, with probability of failure given by &lt;em&gt;1 - p&lt;/em&gt;; by independence, we have the term&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=(1-p)^{k-1}&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?(1-p)^{k-1}&#34; title=&#34;(1-p)^{k-1}&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Then, on trial &lt;em&gt;k&lt;/em&gt;, the streak of failures is broken. No matter how large the streak, the probability that the next outcome is a success is always &lt;em&gt;p&lt;/em&gt;.&lt;a href=&#34;#note1&#34; id=&#34;note1ref&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; Again, by independence, we include&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=p&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?p&#34; title=&#34;p&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;at the end of the product.&lt;/p&gt;
&lt;p&gt;The name of the distribution stems from the fact that the sequence of probabilities is geometric; that is, each term after the first is found by multiplying the previous one by a fixed, non-zero number called the &lt;em&gt;common ratio&lt;/em&gt;. In the case of the geometric distribution, the common ratio is &lt;em&gt;1 - p&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The introduction of the geometric distribution was motivated by the question: what is the probability that I will need &lt;em&gt;k&lt;/em&gt; trials until I obtain the first success in a binary experiment (e.g. a coin flip)? A related question is this: Suppose I run &lt;em&gt;k&lt;/em&gt; trials of the experiment. What is the probability that I have &lt;em&gt;at least one&lt;/em&gt; success? This is given by the cumulative distribution function (CDF) of the geometric distribution:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=Pr(X&amp;space;\leq&amp;space;k)&amp;space;=&amp;space;1&amp;space;-&amp;space;(1-p)^{k}&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?Pr(X&amp;space;\leq&amp;space;k)&amp;space;=&amp;space;1&amp;space;-&amp;space;(1-p)^{k}&#34; title=&#34;Pr(X \leq k) = 1 - (1-p)^{k}&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hopefully the interpretation of this formula is straightforward by now. In &lt;em&gt;k&lt;/em&gt; trials, the probability of them all being a failure is&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.codecogs.com/eqnedit.php?latex=(1-p)^{k}&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://latex.codecogs.com/gif.latex?(1-p)^{k}&#34; title=&#34;(1-p)^{k}&#34; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The &lt;em&gt;complement&lt;/em&gt; of this probability corresponds to &lt;em&gt;anything else&lt;/em&gt; that could happen: 1 success, &lt;em&gt;k&lt;/em&gt; successes, or any number in between. Thus we subtract the probability of &lt;em&gt;k&lt;/em&gt; failures from 1 to obtain the probability of the complement. This corresponds to the related questions posed initially: what is the probability of at least one success in &lt;em&gt;k&lt;/em&gt; independent runs of a Bernoulli trial?&lt;a href=&#34;#note2&#34; id=&#34;note2ref&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a id=&#34;note1&#34; href=&#34;#note1ref&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; See the 
&lt;a href=&#34;https://en.wikipedia.org/wiki/Gambler%27s_fallacy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gambler&amp;rsquo;s fallacy&lt;/a&gt;
 if you don&amp;rsquo;t believe that the next trial always has probability &lt;em&gt;p&lt;/em&gt; of success!&lt;/p&gt;
&lt;p&gt;&lt;a id=&#34;note2&#34; href=&#34;#note2ref&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; This question has many applications. A fun one is the probability of obtaining a rare drop from a video game boss after a certain number of kills.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
